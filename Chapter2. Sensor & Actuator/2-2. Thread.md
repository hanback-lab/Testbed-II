# 스레드
운영체제는 **스케줄링(Scheduling)** 을 통해 여러 프로그램을 동시에 실행하는 듯한 환경을 제공합니다. 초기 유닉스 계열 운영체제에서 실행의 기본 단위는 프로세스였으나, 이후 실행 흐름을 더욱 효율적으로 관리하기 위해 스레드(Thread) 개념이 도입되었습니다.

## 프로세스 생성과 메모리 관리
유닉스 및 리눅스 환경에서는 fork() 시스템 콜을 통해 현재 프로세스를 복제하여 새로운 프로세스를 생성할 수 있습니다. 이때 기존 프로세스는 부모 프로세스, 복제된 프로세스는 자식 프로세스가 됩니다.

논리적으로 fork()는 부모 프로세스의 주소 공간 전체를 복제하는 방식이지만, 현대 운영체제는 자원 효율성을 위해 Copy-on-Write (CoW) 기법을 사용합니다. 이는 실제 데이터 수정이 발생하기 전까지 메모리 복사를 지연시켜 시스템 부하를 최소화하는 방식입니다.

## 멀티 프로세싱과 IPC의 한계
프로세스 단위의 실행 흐름 분리는 운영체제의 메모리 보호 정책에 따라 각 프로세스가 독립된 가상 메모리 공간을 가짐을 의미합니다. 이는 안정성 측면에서는 유리하지만, 주소 공간과 커널 자원 관리 비용이 커지는 단점이 있습니다.

특히 프로세스 간에는 데이터를 직접 공유할 수 없으므로, 공유 메모리(Shared Memory), 파이프(Pipe), 소켓(Socket) 등 별도의 IPC(Inter-Process Communication) 메커니즘이 필요합니다. IPC는 커널 모드 진입과 데이터 직렬화 등으로 인해 상대적으로 높은 오버헤드를 발생시킵니다.

## 스레드의 탄생과 자원 공유
이러한 프로세스의 무거운 비용을 해결하기 위해 등장한 것이 스레드입니다. 스레드는 프로세스 내에서 독립적으로 실행되는 흐름의 단위입니다.

독립 영역: 각 스레드는 고유의 스택(Stack) 영역과 프로그램 카운터(PC), 레지스터 세트를 포함한 실행 컨텍스트를 가집니다.

공유 영역: 동일 프로세스 내의 스레드들은 힙(Heap) 영역, 전역 변수(Data), 코드(Code) 영역을 공유합니다.

이러한 구조는 자원 생성 및 컨텍스트 스위칭 비용을 낮추지만, 여러 스레드가 공유 자원에 동시에 접근할 때 발생하는 데이터 레이스(Data Race) 문제를 야기합니다. 이를 해결하기 위해 **뮤텍스(Mutex)** 나 **세마포어(Semaphore)** 와 같은 동기화 기법이 필수적으로 사용됩니다.

## 파이썬 CPython의 GIL (Global Interpreter Lock)
파이썬의 기본 인터프리터인 CPython은 멀티 스레드 환경에서 객체의 참조 카운터(Reference Count)와 인터프리터 내부 상태를 안전하게 보호하기 위해 **GIL(Global Interpreter Lock)** 을 사용합니다.

GIL은 한 번에 하나의 스레드만이 파이썬 바이트코드를 실행할 수 있도록 제한합니다. 이로 인해 I/O 밀집형 작업에서는 효율적일 수 있으나, 다중 코어를 활용해야 하는 CPU 연산 중심 작업에서는 물리적인 병렬 실행(Parallelism)에 제약이 발생하게 됩니다.

파이썬 프로그램은 기본적으로 하나의 메인 스레드에서 시작됩니다. 예를 들어, 무한 루프를 수행하는 함수를 별도의 스레드로 분리하면 메인 스레드와 **논리적 동시성(Concurrency)** 을 갖고 실행될 수 있습니다. 메인 스레드가 키보드 인터럽트(SIGINT) 등을 감지하여 종료 신호를 보내면, 실행 중인 하위 스레드들이 자원을 정리하고 안전하게 종료되도록 설계하는 것이 멀티 스레드 프로그래밍의 일반적인 구조입니다.

```python
import threading, time 
is_stoped = False

def work_thread(symbol):
    global is_stoped
    while not is_stoped:
        print(symbol, end='', flush=True)
        time.sleep(20/1000)

work = threading.Thread(target=work_thread, args=('o',), daemon=True)
work.start()

try:
    while True:
        print('x', end='', flush=True)
        time.sleep(20/1000)
except KeyboardInterrupt:
    is_stoped = True
    work.join()  
```
```out
oxoxxoxoxoxoxoxoxoxoxoxooxoxoxxooxxoxoxoxoxoxoxoxooxoxoxoxoxoxxoxoxo^C
```

다음과 같이 메인스레드 이외에 두개 또는 여러 개의 스레드를 생성하여 동작하는 것도 가능합니다.

```python
import threading, time

def thread_a(n):
    for i in range(1,n+1):
        print("thread a :", i)
        time.sleep(0.5)

def thread_b(n):
    for i in range(1, n+5):   
        print("thread b :", i)
        time.sleep(0.7)

t1 = threading.Thread(target=thread_a, args=(5,))
t1.start()
t2 = threading.Thread(target=thread_b, args=(5,)) 
t2.start()

for i in range(3, 0, -1):
    print("main :", i)
    time.sleep(1)

t1.join()
t2.join()
```

```out
thread a : 1
thread b : 1
main : 3
thread a : 2
thread b : 2
main : 2
thread a : 3
thread b : 3
thread a : 4
main : 1
thread a : 5
thread b : 4
thread b : 5
thread b : 6
thread b : 7
thread b : 8
thread b : 9
```

동작 결과를 확인해보면 메인 스레드와 thread_a 와 thread_b가 각각 동시에 작업을 수행하며 지정된 문자를 출력하는 것을 볼 수 있습니다. 이 상태에서 전역 변수로 생성되어 있는 변수에 각스레드에서 모두 접근하게 된다면 스레드가 접근하는 순서에 따라서 변수의 값이 원하지 않는 상태로 변하는 경우도 발생할 수 있습니다. 

이러한 상태를 경쟁 상태(Race Condition)라고 합니다. 이를 해결하기 위해서는 Lock 객체를 활용하여 스레드에서 같은 자원에 접근하는 순간에 먼저 접근한 스레드에서 자원을 활용하고 반환하고 나서 다시 활용하도록 동기화하여야 합니다.

```python
from threading import Thread, Lock
import time

lock = Lock()
number = 0

def thread_a():
    global number
    lock.acquire()
    for i in range(1,5):
        number += i 
        print("thread a :", number)
        time.sleep(0.5)
    lock.release()

def thread_b():
    global number
    lock.acquire()
    for i in range(1,5):
        number -= i 
        print("thread b :", number)
        time.sleep(0.5)
    lock.release()

t1 = Thread(target=thread_a)
t2 = Thread(target=thread_b)

t1.start()
time.sleep(2)
t2.start()

t1.join()
t2.join()
```

```out
thread a : 1
thread a : 3
thread a : 6
thread a : 10
thread b : 9
thread b : 7
thread b : 4
thread b : 0
```

## 스레드를 활용한 커튼 제어 및 피드백 확인 
액츄에이터의 피드백 데이터는 명령을 실행하고 나서 실제 동작이 이루어진 후 다시 반환 되는 형태로, 구성하더라도 제어와 동시에 피드백 데이터를 수신하는것은 불가능합니다. 따라서 제어 신호를 전달하는 구문과 현재 제어상태를 확인하는 구문을 분리하여 동작 시킨다면 제어 신호가 전달되고 피드백 데이터가 수신되는데까지 소요되는 시간도 확인할 수 있고, 상태값의 변화에 따라 제어 명령이 정상적으로 수행했는지 빠른 시간에 확인이 가능합니다. 아래 코드는 커튼을 메인스레드에서 제어 명령을 송신하고 별도의 스레드에서 피드백 데이터를 확인하여 출력하는 내용입니다. 

```python
from testbed.actuator import Curtain
import time, threading 

curtain = Curtain()
thread_run = True

def print_state():
    global curtain, stop
    while thread_run:
        print(curtain.state)
        time.sleep(0.1)

cth = threading.Thread(target=print_state,daemon=True)
cth.start()

curtain.open()
time.sleep(2)
curtain.stop()
time.sleep(2)
curtain.open()
time.sleep(2)
curtain.close()
time.sleep(2)
curtain.stop()
time.sleep(2)
curtain.close()
time.sleep(2)

thread_run = False
cth.join()
```

```out
{'ts': 1609459213, 'state': 'OPENING'}
{'ts': 1609459213, 'state': 'OPENING'}
{'ts': 1609459213, 'state': 'OPENING'}
{'ts': 1609459213, 'state': 'OPENING'}
{'ts': 1609459213, 'state': 'OPENING'}
...중략...
{'ts': 1609459216, 'state': 'OPENED'}
{'ts': 1609459216, 'state': 'OPENED'}
{'ts': 1609459216, 'state': 'OPENED'}
...중략...
{'ts': 1609459218, 'state': 'CLOSING'}
{'ts': 1609459218, 'state': 'CLOSING'}
{'ts': 1609459218, 'state': 'CLOSING'}
...중략...
{'ts': 1609459221, 'state': 'CLOSED'}
{'ts': 1609459221, 'state': 'CLOSED'}
{'ts': 1609459221, 'state': 'CLOSED'}
```
